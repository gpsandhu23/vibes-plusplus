# vibes-plusplus

## Developer Centric Evaluation Framework for AI Dev Tools

### What developers want from AI CodeGen Tools

- **Code Quality**: Generate production level high quality code.
- **Context Retrieval**: Retrieve context from other files wihtout having to copy paste context into LLM prompts.
- **Style guide adherence**: Adhere to the style guide for the project.


### How do we currently evaluate AI CodeGen Tools

- **HumanEval**: Benchmark used by model providers to evaluate the accuracy of their models.
- **SWE-Bench**: Benchmark used by CodeGen providers to evaluate the capabilities of their tools.


### What actually happens when a new tool is released?

Developers rely on mostly vibes to determine if a new tool is any good.

### How does Vibes++ help?
Vibes++ is setup to easily evaluate the new tools on the same metrics that developers care about.
